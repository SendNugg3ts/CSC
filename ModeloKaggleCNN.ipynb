{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib as imp\n",
    "import datacleaner\n",
    "import datetime\n",
    "imp.reload(datacleaner)\n",
    "\n",
    "from datacleaner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 24 #number of days that make up a sequence\n",
    "multivariate = 13 #number of features used by the model (using incidents to predict incidents)\n",
    "multisteps = 24 #number of days to forecast – we will forecast the next 7 days\n",
    "# cv_splits = 3 #time series cross validator\n",
    "epochs = 50\n",
    "batch_size = 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "bd = pd.read_csv(r\"training_data.csv\", na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_dados(bd):\n",
    "    bd = ordernar(bd)\n",
    "    bd = RoadsCleaner(bd)\n",
    "    #bd = data(bd)\n",
    "    bd = valores_em_falta(bd)\n",
    "    bd = eliminar(bd)\n",
    "    bd = incidentsNumbers(bd)\n",
    "    bd = luminosidade(bd)\n",
    "    bd = rainNumbers(bd)\n",
    "    bd = delayNumbers(bd)\n",
    "    bd = removeOutlier(bd)\n",
    "    indice_treino, indice_val=split_data(bd, perc=10)\n",
    "    escala, bd = data_normalization(bd, norm_range=(-1, 1))\n",
    "    return bd,indice_treino,indice_val,escala\n",
    "    \n",
    "bd,indice_treino,indice_val,escala=tratar_dados(bd)\n",
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.index = pd.to_datetime(bd[\"record_date\"], format=\"%Y-%m-%d %H:%M:00\")\n",
    "serie(bd,\"incidents\")\n",
    "newBd = bd[[\"incidents\",\"record_date\"]]\n",
    "bd.pop(\"record_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = bd\n",
    "temp = temp.resample(\"H\").interpolate(method=\"time\")\n",
    "temp =temp[temp.index.month !=8]\n",
    "print(temp)\n",
    "fig=plt.figure()\n",
    "plt.plot(temp[\"incidents\"])\n",
    "spacing =10\n",
    "fig.subplots_adjust(right=spacing)\n",
    "plt.show()\n",
    "print(temp[\"incidents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(df, window_size=5):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - window_size):\n",
    "        row = df_as_np[i:i + window_size]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i + window_size][8]  # Última coluna contém a variável de destino (incidentes)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 48\n",
    "X1, y1 = df_to_X_y(temp, WINDOW_SIZE)\n",
    "X1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1 = X1[:6000], y1[:6000]\n",
    "X_val1, y_val1 = X1[6000:7000], y1[6000:7000]\n",
    "X_test1, y_test1 = X1[7000:], y1[7000:]\n",
    "X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_learning_curves(history, epochs):\n",
    "#     #accuracies and losses\n",
    "#     acc = history.history['accuracy']\n",
    "#     val_acc = history.history['val_accuracy']\n",
    "#     loss = history.history['loss']\n",
    "#     val_loss = history.history['val_loss']\n",
    "#     epochs_range = range(epochs)\n",
    "#     #creating figure\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "#     plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.title('Training/Validation Accuracy')\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(epochs_range, loss, label='Training Loss')\n",
    "#     plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.title('Training/Validation Loss')\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_train_data(data, approach='history'):\n",
    "#     plt.figure(figsize=(8,6))\n",
    "#     if approach == 'history':\n",
    "#         plt.title('Model train vs val loss per Training Split')\n",
    "#         plt.ylabel('Training RMSE (Normalized)')\n",
    "#         plt.xlabel('Epoch')\n",
    "#         for hist, i in zip(data, range(len(data))):  \n",
    "#             plt.subplot(3,1,i+1)      \n",
    "#             plt.plot(hist.epoch, hist.history['loss'])\n",
    "#             plt.plot(hist.epoch, hist.history['val_loss'])\n",
    "#             plt.xlim([0, max(hist.epoch)])  \n",
    "#             plt.legend(['Training split ' + str(i+1) + ' - train loss', 'Training split ' + str(i+1) + ' - val loss'], loc='upper right')\n",
    "#         plt.show()   \n",
    "#     elif approach == 'loss':\n",
    "#         plt.figure(figsize=(6,3))\n",
    "#         plt.plot(range(len(data)), data)\n",
    "#         plt.title('RMSE value per Timeseries split')\n",
    "#         plt.ylabel('Evaluation RMSE')\n",
    "#         plt.xlabel('Timeseries Splits')\n",
    "#         plt.xlim([0, 2])\n",
    "#         plt.ylim([0, (np.amax(data)+2)])\n",
    "#         plt.show()\n",
    "\n",
    "# def compile_and_fit(model, epochs, batch_size):\n",
    "#     #compile\n",
    "#     model.compile(loss = rmse, optimizer = tf.keras.optimizers.Adam(), metrics = ['mae', rmse])\n",
    "#     #fit\n",
    "#     hist_list = list()\n",
    "#     loss_list = list()\n",
    "#     #Time Series Cross Validator\n",
    "#     tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "#     for train_index, test_index in tscv.split(X):\n",
    "#         train_idx, val_idx = split_data(train_index, perc=10) #further split into training and validation sets\n",
    "#         #build data\n",
    "#         X_train, y_train = X[train_idx], y[train_idx]\n",
    "#         X_val, y_val = X[val_idx], y[val_idx]\n",
    "#         X_test, y_test = X[test_index], y[test_index]\n",
    "#         history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "#         epochs=epochs, batch_size=batch_size, shuffle=False)\n",
    "#         metrics = model.evaluate(X_test, y_test)\n",
    "#         hist_list.append(history)\n",
    "#         loss_list.append(metrics[2])\n",
    "#     plot_train_data(hist_list, approach='history')\n",
    "#     # plot_learning_curves(loss_list, approach='loss')\n",
    "#     return model, hist_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(timesteps, features, filters=16, kernel_size=5, pool_size=2):\n",
    "    #using the Functional API\n",
    "    inputs = tf.keras.layers.Input(shape=(timesteps, features))\n",
    "    print(inputs)\n",
    "    #microarchitecture\n",
    "    x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "    activation='relu', data_format='channels_last')(inputs)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size=pool_size,\n",
    "    data_format='channels_first')(x)\n",
    "    #last layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(filters)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    #the model\n",
    "    cnnModel = tf.keras.Model(inputs=inputs, outputs=outputs, name='KaggleCNN_model')\n",
    "    tf.keras.utils.plot_model(cnnModel, 'Kagglecnn.png', show_shapes=True)\n",
    "    return cnnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(timesteps, multivariate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp1 = ModelCheckpoint('model_KaggleCNN/model.h5', save_best_only=True)\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp1 = ModelCheckpoint('model_KaggleCNN/model.h5', save_best_only=True)\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=100, callbacks=[cp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('modelKaggleCNN/modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_train1).flatten()\n",
    "escala_predictions = MinMaxScaler()\n",
    "escala_actuals = MinMaxScaler()\n",
    "\n",
    "escala_predictions.fit(train_predictions.reshape(-1, 1))\n",
    "escala_actuals.fit(y_train1.reshape(-1, 1))\n",
    "\n",
    "train_predictions_unscaled = escala_predictions.inverse_transform(train_predictions.reshape(-1, 1))\n",
    "y_train1_unscaled = escala_actuals.inverse_transform(y_train1.reshape(-1, 1))\n",
    "train_predictions_unscaled += 3\n",
    "y_train1_unscaled += 3\n",
    "train_results = pd.DataFrame(data={'Train Predictions': train_predictions_unscaled.flatten(), 'Actuals': y_train1_unscaled.flatten()})\n",
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Resultados do Treino')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Valores')\n",
    "\n",
    "plt.plot(train_results['Train Predictions'][:500], color='blue', linestyle='--', label='Previsões de Treino')\n",
    "plt.plot(train_results['Actuals'][:500], color='red', linestyle='-', label='Valores Reais')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(X_val1).flatten()\n",
    "escala_predictions = MinMaxScaler()\n",
    "escala_actuals = MinMaxScaler()\n",
    "\n",
    "escala_predictions.fit(val_predictions.reshape(-1, 1))\n",
    "escala_actuals.fit(y_val1.reshape(-1, 1))\n",
    "\n",
    "val_predictions_unscaled = escala_predictions.inverse_transform(val_predictions.reshape(-1, 1))\n",
    "y_val1_unscaled = escala_actuals.inverse_transform(y_val1.reshape(-1, 1))\n",
    "val_predictions_unscaled += 3\n",
    "y_val1_unscaled += 3\n",
    "val_results = pd.DataFrame(data={'Val Predictions': val_predictions_unscaled.flatten(), 'Actuals': y_val1_unscaled.flatten()})\n",
    "val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Resultados da Validação')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Valores')\n",
    "\n",
    "plt.plot(val_results['Val Predictions'][:100], color='blue', linestyle='--', label='Previsões da Validação')\n",
    "plt.plot(val_results['Actuals'][:100], color='red', linestyle='-', label='Valores Reais')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test1).flatten()\n",
    "escala_predictions = MinMaxScaler()\n",
    "escala_actuals = MinMaxScaler()\n",
    "\n",
    "escala_predictions.fit(test_predictions.reshape(-1, 1))\n",
    "escala_actuals.fit(y_test1.reshape(-1, 1))\n",
    "\n",
    "test_predictions_unscaled = escala_predictions.inverse_transform(test_predictions.reshape(-1, 1))\n",
    "y_test1_unscaled = escala_actuals.inverse_transform(y_test1.reshape(-1, 1))\n",
    "test_predictions_unscaled += 3\n",
    "y_test1_unscaled += 3\n",
    "test_results = pd.DataFrame(data={'Test Predictions': test_predictions_unscaled.flatten(), 'Actuals': y_test1_unscaled.flatten()})\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Resultados de Teste')\n",
    "plt.xlabel('índice')\n",
    "plt.ylabel('Valores')\n",
    "\n",
    "plt.plot(test_results['Test Predictions'][:300], color='blue', linestyle='--', label='Previsões do Teste')\n",
    "plt.plot(test_results['Actuals'][:300], color='red', linestyle='-', label='Valores Reais')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, df, timesteps, multisteps, scaler):\n",
    "    input_seq = df[-timesteps:].values #getting the last sequence of known value\n",
    "    inp = input_seq\n",
    "    predictions = list()\n",
    "    for _ in range(1, multisteps+1):\n",
    "        inp = inp.reshape(1, timesteps, 1)\n",
    "        yhat = model.predict(inp)\n",
    "        yhat_inversed = scaler.inverse_transform(yhat)\n",
    "        predictions.append(yhat_inversed[0][0])\n",
    "        #prepare new input to forecast the next day\n",
    "        inp = np.append(inp[0], yhat)\n",
    "        inp = inp[-timesteps:]\n",
    "    return predictions\n",
    "\n",
    "def plot_forecast(data, forecasts):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(range(len(data)), data, color='green', label='Confirmed')\n",
    "    plt.plot(range(len(data)-1, len(data)+len(forecasts)-1), forecasts, color='red', label='Forecasts')\n",
    "    plt.title('Number of incidents')\n",
    "    plt.ylabel('Incidents')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = forecast(model, bd, WINDOW_SIZE, multisteps=multisteps, scaler=escala)\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(bd, forecasts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
