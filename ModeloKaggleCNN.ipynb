{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib as imp\n",
    "import datacleaner\n",
    "import datetime\n",
    "imp.reload(datacleaner)\n",
    "\n",
    "from datacleaner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 48 #number of days that make up a sequence\n",
    "multivariate = 13 #number of features used by the model (using incidents to predict incidents)\n",
    "multisteps = 24 #number of days to forecast – we will forecast the next 7 days\n",
    "# cv_splits = 3 #time series cross validator\n",
    "epochs = 50\n",
    "batch_size = 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "bd = pd.read_csv(r\"training_data.csv\", na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>magnitude_of_delay</th>\n",
       "      <th>delay_in_seconds</th>\n",
       "      <th>affected_roads</th>\n",
       "      <th>record_date</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>avg_atm_pressure</th>\n",
       "      <th>avg_humidity</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>avg_precipitation</th>\n",
       "      <th>avg_rain</th>\n",
       "      <th>incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>2021-03-15 23:00</td>\n",
       "      <td>DARK</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>385</td>\n",
       "      <td>N101,</td>\n",
       "      <td>2021-12-25 18:00</td>\n",
       "      <td>DARK</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>69</td>\n",
       "      <td>,</td>\n",
       "      <td>2021-03-12 15:00</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>MAJOR</td>\n",
       "      <td>2297</td>\n",
       "      <td>N101,R206,N105,N101,N101,N101,N101,N101,N101,N...</td>\n",
       "      <td>2021-09-29 09:00</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "      <td>Very_High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guimaraes</td>\n",
       "      <td>UNDEFINED</td>\n",
       "      <td>0</td>\n",
       "      <td>N101,N101,N101,N101,N101,</td>\n",
       "      <td>2021-06-13 11:00</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sem Chuva</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_name magnitude_of_delay  delay_in_seconds  \\\n",
       "0  Guimaraes          UNDEFINED                 0   \n",
       "1  Guimaraes          UNDEFINED               385   \n",
       "2  Guimaraes          UNDEFINED                69   \n",
       "3  Guimaraes              MAJOR              2297   \n",
       "4  Guimaraes          UNDEFINED                 0   \n",
       "\n",
       "                                      affected_roads       record_date  \\\n",
       "0                                                  ,  2021-03-15 23:00   \n",
       "1                                              N101,  2021-12-25 18:00   \n",
       "2                                                  ,  2021-03-12 15:00   \n",
       "3  N101,R206,N105,N101,N101,N101,N101,N101,N101,N...  2021-09-29 09:00   \n",
       "4                          N101,N101,N101,N101,N101,  2021-06-13 11:00   \n",
       "\n",
       "  luminosity  avg_temperature  avg_atm_pressure  avg_humidity  avg_wind_speed  \\\n",
       "0       DARK             12.0            1013.0          70.0             1.0   \n",
       "1       DARK             12.0            1007.0          91.0             1.0   \n",
       "2      LIGHT             14.0            1025.0          64.0             0.0   \n",
       "3      LIGHT             15.0            1028.0          75.0             1.0   \n",
       "4      LIGHT             27.0            1020.0          52.0             1.0   \n",
       "\n",
       "   avg_precipitation   avg_rain  incidents  \n",
       "0                0.0  Sem Chuva       None  \n",
       "1                0.0  Sem Chuva       None  \n",
       "2                0.0  Sem Chuva        Low  \n",
       "3                0.0  Sem Chuva  Very_High  \n",
       "4                0.0  Sem Chuva       High  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lipe\\Desktop\\Universidade e coisas minhas\\Programming\\CSC\\datacleaner.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bd['magnitude_of_delay'][i] = None\n",
      "c:\\Users\\Lipe\\Desktop\\Universidade e coisas minhas\\Programming\\CSC\\datacleaner.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bd[\"delay_in_seconds\"][count] = valor\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     escala, bd \u001b[39m=\u001b[39m data_normalization(bd, norm_range\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m bd,indice_treino,indice_val,escala\n\u001b[1;32m---> 16\u001b[0m bd,indice_treino,indice_val,escala\u001b[39m=\u001b[39mtratar_dados(bd)\n\u001b[0;32m     17\u001b[0m bd\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36mtratar_dados\u001b[1;34m(bd)\u001b[0m\n\u001b[0;32m     11\u001b[0m bd \u001b[39m=\u001b[39m removeOutlier(bd)\n\u001b[0;32m     12\u001b[0m indice_treino, indice_val\u001b[39m=\u001b[39msplit_data(bd, perc\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m escala, bd \u001b[39m=\u001b[39m data_normalization(bd, norm_range\u001b[39m=\u001b[39;49m(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m bd,indice_treino,indice_val,escala\n",
      "File \u001b[1;32mc:\\Users\\Lipe\\Desktop\\Universidade e coisas minhas\\Programming\\CSC\\datacleaner.py:111\u001b[0m, in \u001b[0;36mdata_normalization\u001b[1;34m(bd, norm_range)\u001b[0m\n\u001b[0;32m    109\u001b[0m numericBd\u001b[39m=\u001b[39mbd\u001b[39m.\u001b[39miloc[:,\u001b[39m0\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[0;32m    110\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler(feature_range\u001b[39m=\u001b[39mnorm_range)\n\u001b[1;32m--> 111\u001b[0m scaler\u001b[39m.\u001b[39;49mfit(numericBd\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m    112\u001b[0m numericBd \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(numericBd\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m    113\u001b[0m bd\u001b[39m.\u001b[39miloc[:,\u001b[39m0\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m numericBd\n",
      "File \u001b[1;32mc:\\Users\\Lipe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Lipe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    465\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    467\u001b[0m     X,\n\u001b[0;32m    468\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    469\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    470\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    471\u001b[0m )\n\u001b[0;32m    473\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    474\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lipe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\Lipe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lipe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "def tratar_dados(bd):\n",
    "    bd = ordernar(bd)\n",
    "    bd = RoadsCleaner(bd)\n",
    "    #bd = data(bd)\n",
    "    bd = valores_em_falta(bd)\n",
    "    bd = eliminar(bd)\n",
    "    bd = incidentsNumbers(bd)\n",
    "    bd = luminosidade(bd)\n",
    "    bd = rainNumbers(bd)\n",
    "    bd = delayNumbers(bd)\n",
    "    bd = removeOutlier(bd)\n",
    "    indice_treino, indice_val=split_data(bd, perc=10)\n",
    "    escala, bd = data_normalization(bd, norm_range=(-1, 1))\n",
    "    return bd,indice_treino,indice_val,escala\n",
    "    \n",
    "bd,indice_treino,indice_val,escala=tratar_dados(bd)\n",
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.index = pd.to_datetime(bd[\"record_date\"], format=\"%Y-%m-%d %H:%M:00\")\n",
    "serie(bd,\"incidents\")\n",
    "newBd = bd[[\"incidents\",\"record_date\"]]\n",
    "bd.pop(\"record_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = bd\n",
    "temp = temp.resample(\"H\").interpolate(method=\"time\")\n",
    "temp =temp[temp.index.month !=8]\n",
    "print(temp)\n",
    "fig=plt.figure()\n",
    "plt.plot(temp[\"incidents\"])\n",
    "spacing =10\n",
    "fig.subplots_adjust(right=spacing)\n",
    "plt.show()\n",
    "print(temp[\"incidents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(df, window_size=5):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - window_size):\n",
    "        row = df_as_np[i:i + window_size]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i + window_size][8]  # Última coluna contém a variável de destino (incidentes)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 48\n",
    "X1, y1 = df_to_X_y(temp, WINDOW_SIZE)\n",
    "X1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1 = X1[:6000], y1[:6000]\n",
    "X_val1, y_val1 = X1[6000:7000], y1[6000:7000]\n",
    "X_test1, y_test1 = X1[7000:], y1[7000:]\n",
    "X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(timesteps, features, filters=16, kernel_size=5, pool_size=2):\n",
    "    #using the Functional API\n",
    "    inputs = tf.keras.layers.Input(shape=(timesteps, features))\n",
    "    print(inputs)\n",
    "    #microarchitecture\n",
    "    x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "    activation='relu', data_format='channels_last')(inputs)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size=pool_size,\n",
    "    data_format='channels_first')(x)\n",
    "    #last layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(filters)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    #the model\n",
    "    cnnModel = tf.keras.Model(inputs=inputs, outputs=outputs, name='KaggleCNN_model')\n",
    "    tf.keras.utils.plot_model(cnnModel, 'Kagglecnn.png', show_shapes=True)\n",
    "    return cnnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(timesteps, multivariate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp1 = ModelCheckpoint('model_KaggleCNN/model.h5', save_best_only=True)\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=100, callbacks=[cp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('modelKaggleCNN/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_train1).flatten()\n",
    "escala_predictions = MinMaxScaler()\n",
    "escala_actuals = MinMaxScaler()\n",
    "\n",
    "escala_predictions.fit(train_predictions.reshape(-1, 1))\n",
    "escala_actuals.fit(y_train1.reshape(-1, 1))\n",
    "\n",
    "train_predictions_unscaled = escala_predictions.inverse_transform(train_predictions.reshape(-1, 1))\n",
    "y_train1_unscaled = escala_actuals.inverse_transform(y_train1.reshape(-1, 1))\n",
    "train_predictions_unscaled += 3\n",
    "y_train1_unscaled += 3\n",
    "train_results = pd.DataFrame(data={'Train Predictions': train_predictions_unscaled.flatten(), 'Actuals': y_train1_unscaled.flatten()})\n",
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Resultados do Treino')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Valores')\n",
    "\n",
    "plt.plot(train_results['Train Predictions'][:500], color='blue', linestyle='--', label='Previsões de Treino')\n",
    "plt.plot(train_results['Actuals'][:500], color='red', linestyle='-', label='Valores Reais')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(X_val1).flatten()\n",
    "escala_predictions = MinMaxScaler()\n",
    "escala_actuals = MinMaxScaler()\n",
    "\n",
    "escala_predictions.fit(val_predictions.reshape(-1, 1))\n",
    "escala_actuals.fit(y_val1.reshape(-1, 1))\n",
    "\n",
    "val_predictions_unscaled = escala_predictions.inverse_transform(val_predictions.reshape(-1, 1))\n",
    "y_val1_unscaled = escala_actuals.inverse_transform(y_val1.reshape(-1, 1))\n",
    "val_predictions_unscaled += 3\n",
    "y_val1_unscaled += 3\n",
    "val_results = pd.DataFrame(data={'Val Predictions': val_predictions_unscaled.flatten(), 'Actuals': y_val1_unscaled.flatten()})\n",
    "val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Resultados da Validação')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Valores')\n",
    "\n",
    "plt.plot(val_results['Val Predictions'][:100], color='blue', linestyle='--', label='Previsões da Validação')\n",
    "plt.plot(val_results['Actuals'][:100], color='red', linestyle='-', label='Valores Reais')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test1).flatten()\n",
    "escala_predictions = MinMaxScaler()\n",
    "escala_actuals = MinMaxScaler()\n",
    "\n",
    "escala_predictions.fit(test_predictions.reshape(-1, 1))\n",
    "escala_actuals.fit(y_test1.reshape(-1, 1))\n",
    "\n",
    "test_predictions_unscaled = escala_predictions.inverse_transform(test_predictions.reshape(-1, 1))\n",
    "y_test1_unscaled = escala_actuals.inverse_transform(y_test1.reshape(-1, 1))\n",
    "test_predictions_unscaled += 3\n",
    "y_test1_unscaled += 3\n",
    "test_results = pd.DataFrame(data={'Test Predictions': test_predictions_unscaled.flatten(), 'Actuals': y_test1_unscaled.flatten()})\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Resultados de Teste')\n",
    "plt.xlabel('índice')\n",
    "plt.ylabel('Valores')\n",
    "\n",
    "plt.plot(test_results['Test Predictions'][:300], color='blue', linestyle='--', label='Previsões do Teste')\n",
    "plt.plot(test_results['Actuals'][:300], color='red', linestyle='-', label='Valores Reais')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, df, timesteps, multisteps, scaler):\n",
    "    input_seq = df[-timesteps:].values #getting the last sequence of known value\n",
    "    inp = input_seq\n",
    "    predictions = list()\n",
    "    for _ in range(1, multisteps+1):\n",
    "        inp = inp.reshape(1, timesteps, 1)\n",
    "        yhat = model.predict(inp)\n",
    "        yhat_inversed = scaler.inverse_transform(yhat)\n",
    "        predictions.append(yhat_inversed[0][0])\n",
    "        #prepare new input to forecast the next day\n",
    "        inp = np.append(inp[0], yhat)\n",
    "        inp = inp[-timesteps:]\n",
    "    return predictions\n",
    "\n",
    "def plot_forecast(data, forecasts):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(range(len(data)), data, color='green', label='Confirmed')\n",
    "    plt.plot(range(len(data)-1, len(data)+len(forecasts)-1), forecasts, color='red', label='Forecasts')\n",
    "    plt.title('Number of incidents')\n",
    "    plt.ylabel('Incidents')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = forecast(model, bd, WINDOW_SIZE, multisteps=multisteps, scaler=escala)\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(bd, forecasts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
